{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Britain and UK Handbooks as Data\n",
    "\n",
    "Created in July and August 2020 for the National Library of Scotland's Data Foundry by Lucy Havens, Digital Library Research Intern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Britain and UK Handbooks Dataset\n",
    "The data consists of digitized text from select Britain and UK Handbooks produced between 1954 and 2005.  A central statistics bureau produced the Handbooks each year to communicate information about the UK that would impress international diplomats.\n",
    "* Data format: digitized text\n",
    "* Data creation process: Optical Character Recognition (OCR)\n",
    "* Data source: https://data.nls.uk/digitised-collections/britain-uk-handbooks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Preparation\n",
    "Import libraries to use for cleaning, summarizing and exploring the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lucy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/lucy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/lucy/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# To prevent SSL certificate failure\n",
    "import os, ssl\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
    "    getattr(ssl, '_create_unverified_context', None)):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Libraries for data loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Libraries for visualization\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Libraries for text analysis\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.text import Text\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nls-text-handbooks folder contains TXT files of digitized text, with numerical names, as well as a CSV inventory file and a TXT ReadMe file.  Load only the TXT files of digitized text and **tokenize** the text (which splits a string into separate words and punctuation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BRITAIN', '1979', '3W', '+', 'L', 'Capita', '!', 'Edinburgh', 'Population', '5']\n"
     ]
    }
   ],
   "source": [
    "corpus_folder = 'data/nls-text-handbooks/'\n",
    "wordlists = PlaintextCorpusReader(corpus_folder, '\\d.*', encoding='latin1')\n",
    "corpus_tokens = wordlists.words()\n",
    "print(corpus_tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to get a sense of how accurately the text has been digitized from this list of 10 words, so let's look at one of these words in context.  To see phrases in which \"Edinburgh\" is used, we can use the concordance() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 20 of 2579 matches:\n",
      "BRITAIN 1979 3W + L Capita ! Edinburgh Population 5 , 196 / GOO ENGLAND A\n",
      "ondon WC1V 6HB 13a Castle Street , Edinburgh EH2 3AR 41 The Hayes , Cardiff CF1\n",
      "ield Liverpool Manchester Bradford Edinburgh Bristol Belfast Coventry Cardiff s\n",
      "Counsellors of State ( the Duke of Edinburgh , the four adult persons next in s\n",
      "ments , accompanied by the Duke of Edinburgh , and undertakes lengthy tours in \n",
      "y government bookshops in London , Edinburgh , Cardiff , Belfast , Manchester ,\n",
      "five Scottish departments based in Edinburgh and known as the Scottish Office .\n",
      " is centred in the Crown Office in Edinburgh . The Parliamentary Draftsmen for \n",
      ". The main seat of the court is in Edinburgh where all appeals are heard . All \n",
      " The Court of Session sits only in Edinburgh , and has jurisdiction to deal wit\n",
      "ersities are : Aberdeen , Dundee , Edinburgh , Glasgow , Heriot - Watt ( Edinbu\n",
      "nburgh , Glasgow , Heriot - Watt ( Edinburgh ), St . Andrews , Stirling , and S\n",
      ". Andrews , Glasgow , Aberdeen and Edinburgh from the fifteenth and sixteenth c\n",
      "the Pentland Hills to the south of Edinburgh . Over 98 per cent of the land in \n",
      " , a major commercial centre , and Edinburgh , Scotland s capital , an administ\n",
      " , bife and Dundee , as well as in Edinburgh , where this and other modern indu\n",
      "c Services Station , East Craigs , Edinburgh , provide scientific and technical\n",
      "similar service between London and Edinburgh in May 1978 and the construction o\n",
      "t England and on the route linking Edinburgh , Newcastle upon Tyne , Birmingham\n",
      "e been introduced from Heathrow to Edinburgh and Belfast . Joint shuttle servic\n"
     ]
    }
   ],
   "source": [
    "t = Text(corpus_tokens)\n",
    "t.concordance('Edinburgh', lines=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm guessing `bife` should be `Fife` as it's closely followed by `Dundee`, but overall not so bad!\n",
    "\n",
    "We can also load individual files from the nls-text-handbooks folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GH', '.', 'fl-', '[', 'IASG0', '>', 'J^RSEI', 'nice', ']', 'ROME']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('data/nls-text-handbooks/205336772.txt', 'r')\n",
    "sample_text = file.read()\n",
    "sample_tokens = word_tokenize(sample_text)\n",
    "sample_tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in this Notebook, we're interested in the entire dataset, so we'll use all its files.  Let's find out just how many files, and just how much text, we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total...\n",
      "  Characters in Handbooks Data: 90573254\n",
      "  Words in Handbooks Data: 16606800\n",
      "  Sentences in Handbooks Data: 584618\n",
      "  Files in Handbooks Data: 50\n"
     ]
    }
   ],
   "source": [
    "def corpusStatistics(plaintext_corpus_read_lists):\n",
    "    total_chars = 0\n",
    "    total_words = 0\n",
    "    total_sents = 0\n",
    "    total_files = 0\n",
    "    for fileid in plaintext_corpus_read_lists.fileids():\n",
    "        total_chars += len(plaintext_corpus_read_lists.raw(fileid))\n",
    "        total_words += len(plaintext_corpus_read_lists.words(fileid))\n",
    "        total_sents += len(plaintext_corpus_read_lists.sents(fileid))\n",
    "        total_files += 1\n",
    "    print(\"Total...\")\n",
    "    print(\"  Characters in Handbooks Data:\", total_chars)\n",
    "    print(\"  Words in Handbooks Data:\", total_words)\n",
    "    print(\"  Sentences in Handbooks Data:\", total_sents)\n",
    "    print(\"  Files in Handbooks Data:\", total_files)\n",
    "\n",
    "corpusStatistics(wordlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across the 50 files that make up the Handbooks dataset, there are over 90 million characters (which could be words, numbers, punctuation, abbreviations, etc.), over 16 million words, and nearly 600,000 sentences.  Of course, OCR isn't perfect, so these numbers are estimates, not precise totals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bife` most likely isn't the only word the OCR incorrectly digitized.  To get a sense of how much of the digitized text we can perform meaningful analysis on, let's figure out how many of NLTK's \"words\" are actually recognizable English words.\n",
    "\n",
    "We'll use [WordNet](https://wordnet.princeton.edu/),* a database of English words, to evaluate which of NLTK's \"words\" are not valid English words.\n",
    "\n",
    "***\n",
    "\n",
    "  *Princeton University \"About WordNet.\" WordNet. Princeton University. 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First,** let's create a list of strings from the words NLTK has identified for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BRITAIN', '1979', '3W', '+', 'L', 'Capita', '!', 'Edinburgh', 'Population', '5']\n"
     ]
    }
   ],
   "source": [
    "str_tokens = [str(word) for word in corpus_tokens]\n",
    "assert(type(str_tokens[0]) == str)  # quick test to make sure the output is as expected\n",
    "print(str_tokens[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are digits and punctuation that won't be recognized as words in WordNet but still provide valuable text data for studying the Handbooks.  For example, in the output above, it looks as though the OCR processed the word `Capital` as `Capita!`, which NLTK has split into two.  Furthermore, the word '1979' is a date that puts the text in context, which would enable one to order information in the text by date.\n",
    "\n",
    "To get an estimate of how accurately OCR digitized the Handbooks, though, we'll use words in the sense that they are recognizable words in the English language.  Let's write a regular expression that can tell us whether a string is a word or abbreviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "isWord = re.compile('[a-zA-z.]+')  # include single letters and abbreviations\n",
    "\n",
    "# ----------- TESTING REGEX -----------\n",
    "# print(isWord.match(\"bife\").group())\n",
    "# print(isWord.match(\"U.S.A.\").group())\n",
    "# print(isWord.match(\"W\").group())\n",
    "# print(isWord.match(\"1979\") == None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lastly,** let's use that regular expression to write a function to distinguish words recognizable English words from unrecognizable strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNonEnglishWords(list_of_strings):\n",
    "    english_only = []\n",
    "    nonenglish = []\n",
    "    for s in list_of_strings:\n",
    "        test = isWord.match(s)            # fails if has characters other than letters or a period\n",
    "        if (test != None):\n",
    "            passed = test.group()   # get the matching string\n",
    "            if wordnet.synsets(passed):  # see if WordNet recognizes the matching string\n",
    "                english_only.append(passed)\n",
    "            else:\n",
    "                nonenglish.append(passed)\n",
    "    return english_only, nonenglish\n",
    "                \n",
    "recognized, unrecognized = removeNonEnglishWords(str_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total alphabetic words recognized in WordNet: 9665798\n",
      "Total alphabetic words NOT reccognized in WordNet: 4009482\n",
      "Percentage of alphabetic words that are unrecognized in WordNet: 41.481127579947355\n"
     ]
    }
   ],
   "source": [
    "print(\"Total alphabetic words recognized in WordNet:\", len(recognized))\n",
    "print(\"Total alphabetic words NOT reccognized in WordNet:\", len(unrecognized))\n",
    "print(\"Percentage of alphabetic words that are unrecognized in WordNet:\", (len(unrecognized)/len(recognized))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summary Statistics\n",
    "\n",
    "Different types of analysis require different subsets of data, so let's create some here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase text\n",
    "lower_str_tokens = [t.lower() for t in str_tokens]\n",
    "lower_recognized = [word.lower() for word in recognized]\n",
    "lower_unrecognized = [word.lower() for word in unrecognized]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude stop words (i.e. the, a, is) - note that the input text must be lowercased!\n",
    "eng_stopwords = set(stopwords.words('english'))\n",
    "no_stopwords = [t for t in lower_corpus_tokens if not t in eng_stopwords]\n",
    "assert(len(no_stopwords) < len(corpus_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['britain', '1979', '3w', '+', 'l', 'capita', '!', 'edinburgh', 'popul', '5', ',', '196', '/', 'goo', 'england', 'area', '130', ',', 'm41sq', '.', 'km', '50', '/', '363sq', '.', 'mile', 'capita', '!', 'london', 'pecul', '4', '-', '6', '/', '351', '/', '000', ';', 'ivy1', 'i', '-', '<', '1', '..', 'i', \"'\", 'i', '&', 'rr', '^', 'xt', ':.', 'u', '.', '5', '%', 'v', '?', 'iq', '^', 'an', 'offici', 'handbook', 'an', 'offici', 'handbook', 'london', ':', 'her', 'majesti', 'stationeri', 'offic', 'â', '©', 'crown', 'copyright', '1979', 'first', 'publish', '1979', 'her', 'majesti', \"'\", 's', 'stationeri', 'offic', 'govern', 'bookshop', '49', 'high', 'holborn', ',', 'london', 'wc1v', '6hb', '13a', 'castl', 'street', ',', 'edinburgh']\n",
      "\n",
      "['britain', '1979', '3w', '+', 'l', 'capit', '!', 'edinburgh', 'pop', '5', ',', '196', '/', 'goo', 'england', 'are', '130', ',', 'm41sq', '.', 'km', '50', '/', '363sq', '.', 'mil', 'capit', '!', 'london', 'pec', '4', '-', '6', '/', '351', '/', '000', ';', 'ivy1', 'i', '-', '<', '1', '..', 'i', \"'\", 'i', '&', 'rr', '^', 'xt', ':.', 'u', '.', '5', '%', 'v', '?', 'iq', '^', 'an', 'off', 'handbook', 'an', 'off', 'handbook', 'london', ':', 'her', 'majesty', 'stationery', 'off', 'â', '©', 'crown', 'copyright', '1979', 'first', 'publ', '1979', 'her', 'majesty', \"'\", 's', 'stationery', 'off', 'govern', 'bookshop', '49', 'high', 'holborn', ',', 'london', 'wc1v', '6hb', '13a', 'castl', 'street', ',', 'edinburgh']\n"
     ]
    }
   ],
   "source": [
    "# Stem the text (reduce words to their root, whether or not the root is a word itself\n",
    "porter = nltk.PorterStemmer()\n",
    "porter_stemmed = [porter.stem(t) for t in lower_str_tokens]\n",
    "print(porter_stemmed[:100])\n",
    "print()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "lancaster_stemmed = [lancaster.stem(t) for t in lower_str_tokens]\n",
    "print(lancaster_stemmed[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['britain', '1979', '3w', '+', 'l', 'caput', '!', 'edinburgh', 'population', '5', ',', '196', '/', 'goo', 'england', 'area', '130', ',', 'm41sq', '.', 'km', '50', '/', '363sq', '.', 'mile', 'caput', '!', 'london', 'peculation', '4', '-', '6', '/', '351', '/', '000', ';', 'ivy1', 'i', '-', '<', '1', '..', 'i', \"'\", 'i', '&', 'rr', '^', 'xt', ':.', 'u', '.', '5', '%', 'v', '?', 'iq', '^', 'an', 'official', 'handbook', 'an', 'official', 'handbook', 'london', ':', 'her', 'majesty', 'stationery', 'office', 'â', '©', 'crown', 'copyright', '1979', 'first', 'published', '1979', 'her', 'majesty', \"'\", 's', 'stationery', 'office', 'government', 'bookshop', '49', 'high', 'holborn', ',', 'london', 'wc1v', '6hb', '13a', 'castle', 'street', ',', 'edinburgh']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize the text (reduce words to their root ONLY if the root is considered a word in WordNet)\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "lemmatized = [wnl.lemmatize(t) for t in lower_str_tokens]\n",
    "print(lemmatized[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens: 86793\n",
      "Unique lowercase tokens: 70922\n",
      "Unique lemmatized (lowercase) tokens: 66172\n",
      "\n",
      "Unique recognized words: 36780\n",
      "Unique recognized lowercase words: 25602\n",
      "Unique unrecognized words: 29107\n",
      "Unique unrecognized lowercase words: 26573\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate tokens from the text (obtain the vocabulary of the text)\n",
    "t_vocab = set(str_tokens)\n",
    "t_vocab_lower = set(lower_str_tokens)\n",
    "lemma_vocab = set(lemmatized)\n",
    "print(\"Unique tokens:\", len(t_vocab))\n",
    "print(\"Unique lowercase tokens:\", len(t_vocab_lower))\n",
    "print(\"Unique lemmatized (lowercase) tokens:\", len(lemma_vocab))\n",
    "print()\n",
    "rec_vocab = set(recognized)\n",
    "rec_vocab_lower = set(lower_recognized)\n",
    "unrec_vocab = set(unrecognized)\n",
    "unrec_vocab_lower = set(lower_unrecognized)\n",
    "print(\"Unique recognized words:\", len(rec_vocab))\n",
    "print(\"Unique recognized lowercase words:\", len(rec_vocab_lower))\n",
    "print(\"Unique unrecognized words:\", len(unrec_vocab))\n",
    "print(\"Unique unrecognized lowercase words:\", len(unrec_vocab_lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('BRITAIN', 'NNP'), ('1979', 'CD'), ('3W', 'CD'), ('+', 'NN'), ('L', 'NNP'), ('Capita', 'NNP'), ('!', '.')], [('Edinburgh', 'NNP'), ('Population', 'NNP'), ('5', 'CD'), (',', ','), ('196', 'CD'), ('/', 'NN'), ('GOO', 'NNP'), ('ENGLAND', 'NNP'), ('Area', 'NNP'), ('130', 'CD'), (',', ','), ('M41sq', 'NNP'), ('.', '.'), ('km', 'VB'), ('50', 'CD'), ('/', 'JJ'), ('363sq', 'CD'), ('.', '.'), ('miles', 'NNS'), ('Capita', 'RB'), ('!', '.')], [('London', 'NNP'), ('Peculation', 'NNP'), ('4', 'CD'), ('-', ':'), ('6', 'CD'), ('/', '$'), ('351', 'CD'), ('/', 'JJ'), ('000', 'CD'), (';', ':'), ('iVY1', 'NN'), ('i', 'SYM'), ('-', ':'), ('<', 'NN'), ('1', 'CD'), ('..', 'NN'), ('i', 'NN'), (\"'\", \"''\"), ('i', 'NN'), ('&', 'CC'), ('rr', 'NN'), ('^', 'NN'), ('xt', 'NNP'), (':.', 'NN')], [('u', 'NN'), ('.', '.')], [('5', 'CD'), ('%', 'NN'), ('V', 'NNP'), ('?', '.'), ('iQ', 'NN'), ('^', 'VBD'), ('An', 'DT'), ('official', 'JJ'), ('handbook', 'NN'), ('An', 'DT'), ('official', 'JJ'), ('handbook', 'NN'), ('London', 'NNP'), (':', ':'), ('Her', 'PRP$'), ('Majestys', 'NNP'), ('Stationery', 'NNP'), ('Office', 'NNP'), ('Â', 'NNP'), ('©', 'NNP'), ('Crown', 'NNP'), ('copyright', 'NN'), ('1979', 'CD'), ('First', 'NNP'), ('published', 'VBD'), ('1979', 'CD'), ('Her', 'NNP'), ('Majesty', 'NNP'), (\"'\", 'POS'), ('s', 'JJ'), ('Stationery', 'NNP'), ('Office', 'NNP'), ('Government', 'NNP'), ('Bookshops', 'NNP'), ('49', 'CD'), ('High', 'NNP'), ('Holborn', 'NNP'), (',', ','), ('London', 'NNP'), ('WC1V', 'NNP'), ('6HB', 'CD'), ('13a', 'CD'), ('Castle', 'NNP'), ('Street', 'NNP'), (',', ','), ('Edinburgh', 'NNP'), ('EH2', 'NNP'), ('3AR', 'CD'), ('41', 'CD'), ('The', 'DT'), ('Hayes', 'NNP'), (',', ','), ('Cardiff', 'NNP'), ('CF1', 'NNP'), ('1JW', 'CD'), ('Brazennose', 'NNP'), ('Street', 'NNP'), (',', ','), ('Manchester', 'NNP'), ('M60', 'NNP'), ('8AS', 'CD'), ('Southey', 'NNP'), ('House', 'NNP'), (',', ','), ('Wine', 'NNP'), ('Street', 'NNP'), (',', ','), ('Bristol', 'NNP'), ('BS1', 'NNP'), ('2BQ', 'CD'), ('258', 'CD'), ('Broad', 'NNP'), ('Street', 'NNP'), (',', ','), ('Birmingham', 'NNP'), ('B1', 'NNP'), ('2HE', 'CD'), ('80', 'CD'), ('Chichester', 'NNP'), ('Street', 'NNP'), (',', ','), ('Belfast', 'NNP'), ('BT1', 'NNP'), ('4JY', 'CD'), ('Government', 'NNP'), ('publications', 'NNS'), ('are', 'VBP'), ('also', 'RB'), ('available', 'JJ'), ('through', 'IN'), ('booksellers', 'NNS'), ('Obtainable', 'NNP'), ('in', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), ('of', 'IN'), ('America', 'NNP'), ('from', 'IN'), ('Pendragon', 'NNP'), ('House', 'NNP'), ('Inc', 'NNP'), ('.', '.'), ('2595', 'CD'), ('East', 'NNP'), ('Bayshore', 'NNP'), ('Road', 'NNP'), ('Palo', 'NNP'), ('Alto', 'NNP'), ('California', 'NNP'), ('94303', 'CD'), ('Â', 'NNP'), ('£', 'VBD'), ('7', 'CD'), ('net', 'JJ'), (\"/*'\", 'NN'), ('i', 'NN'), ('X', 'NNP'), ('.', '.'), ('0', 'CD'), ('^', 'JJ'), ('ir', 'NN'), ('>', 'NNP'), ('O', 'NNP'), ('o', 'VBD'), ('ISBN', 'NNP'), ('0', 'CD'), ('11', 'CD'), ('700971', 'CD'), ('7', 'CD'), ('Contents', 'NNPS'), ('Introduction', 'NNP'), ('Page', 'NNP'), ('ix', 'VBZ'), ('1', 'CD'), ('The', 'DT'), ('Land', 'NNP'), ('and', 'CC'), ('the', 'DT'), ('People', 'NNPS'), ('The', 'DT'), ('Physical', 'NNP'), ('Background', 'NNP'), ('The', 'DT'), ('Demographic', 'NNP'), ('Background', 'NNP'), ('The', 'DT'), ('Social', 'NNP'), ('Framework', 'NNP'), ('2', 'CD'), ('Government', 'NNP'), ('General', 'NNP'), ('Survey', 'NNP'), ('The', 'DT'), ('Monarchy', 'NNP'), ('Parliament', 'NNP'), ('The', 'DT'), ('Privy', 'NNP'), ('Council', 'NNP'), ('Her', 'NNP'), ('Majesty', 'NNP'), (\"'\", 'POS'), ('s', 'JJ'), ('Government', 'NNP'), ('Government', 'NNP'), ('Departments', 'VBZ'), ('The', 'DT'), ('Civil', 'NNP'), ('Service', 'NNP'), ('Local', 'NNP'), ('Government', 'NNP'), ('The', 'DT'), ('Fire', 'NNP'), ('Services', 'NNPS'), ('3', 'CD'), ('Membership', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('European', 'NNP'), ('Community', 'NNP'), ('4', 'CD'), ('Justice', 'NNP'), ('and', 'CC'), ('the', 'DT'), ('Law', 'NNP'), ('The', 'DT'), ('Law', 'NNP'), ('Criminal', 'NNP'), ('Justice', 'NNP'), ('Civil', 'NNP'), ('Justice', 'NNP'), ('Administration', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Law', 'NNP'), ('5', 'CD'), ('Defence', 'NNP'), ('Policy', 'NNP'), ('Planning', 'NNP'), ('and', 'CC'), ('Control', 'NNP'), ('Deployment', 'NNP'), ('The', 'DT'), ('Armed', 'NNP'), ('Forces', 'NNP'), ('Civil', 'NNP'), ('Defence', 'NNP'), ('Defence', 'NNP'), ('Procurement', 'NNP'), ('6', 'CD'), ('Social', 'NNP'), ('Welfare', 'NNP'), ('National', 'NNP'), ('Health', 'NNP'), ('Service', 'NNP'), ('Personal', 'NNP'), ('Social', 'NNP'), ('Services', 'NNPS'), ('Social', 'NNP'), ('Security', 'NNP'), ('Voluntary', 'NNP'), ('Services', 'NNPS'), ('Equal', 'NNP'), ('Opportunities', 'NNP'), ('for', 'IN'), ('Women', 'NNP'), ('Race', 'NNP'), ('Relations', 'NNP'), ('7', 'CD'), ('Education', 'NNP'), ('ThejYouth', 'NNP'), ('Service', 'NNP'), ('19', 'CD'), ('19', 'CD'), ('20', 'CD'), ('23', 'CD'), ('35', 'CD'), ('36', 'CD'), ('39', 'CD'), ('55', 'CD'), ('61', 'CD'), ('68', 'CD'), ('71', 'CD'), ('76', 'CD'), ('76', 'CD'), ('76', 'CD'), ('94', 'CD'), ('98', 'CD'), ('103', 'CD'), ('103', 'CD'), ('104', 'CD'), ('105', 'CD'), ('106', 'CD'), ('111', 'CD'), ('111', 'CD'), ('113', 'CD'), ('113', 'CD'), ('122', 'CD'), ('126', 'CD'), ('132', 'CD'), ('134', 'CD'), ('135', 'CD'), ('137', 'CD'), ('154', 'CD'), ('8', 'CD'), ('Planning', 'NN'), ('and', 'CC'), ('the', 'DT'), ('Environment', 'NNP'), ('157', 'CD'), ('Control', 'NNP'), ('of', 'IN'), ('Pollution', 'NNP'), ('105', 'CD'), ('Voluntary', 'NNP'), ('Organisations', 'NNP'), ('170', 'CD'), ('9', 'CD'), ('Housing', 'VBG'), ('10', 'CD'), ('The', 'DT'), ('Churches', 'NNP'), ('173', 'CD'), ('180', 'CD'), ('Page', 'NN'), ('11', 'CD'), ('The', 'DT'), ('National', 'NNP'), ('Economy', 'NNP'), ('184', 'CD'), ('Economic', 'NNP'), ('Development', 'NNP'), ('184', 'CD'), ('Economic', 'NNP'), ('Management', 'NNP'), ('188', 'CD'), ('National', 'NNP'), ('Income', 'NNP'), ('and', 'CC'), ('Expenditure', 'NNP'), ('190', 'CD'), ('The', 'DT'), ('External', 'NNP'), ('Position', 'NNP'), ('194', 'CD'), ('12', 'CD'), ('Industry', 'NN'), ('196', 'CD'), ('Organisation', 'NN'), ('and', 'CC'), ('Production', 'NNP'), ('196', 'CD'), ('The', 'DT'), ('Government', 'NNP'), ('and', 'CC'), ('Industry', 'NNP'), ('207', 'CD'), ('Consumer', 'NNP'), ('Protection', 'NNP'), ('and', 'CC'), ('Competition', 'NNP'), ('Policy', 'NNP'), ('21', 'CD'), ('3', 'CD'), ('Manufacturing', 'NN'), ('Industries', 'NNS'), ('215', 'CD'), ('Construction', 'NNP'), ('233', 'CD'), ('Distributive', 'NNP'), ('and', 'CC'), ('Service', 'NNP'), ('Trades', 'NNP'), ('235', 'CD'), ('13', 'CD'), ('Energy', 'NNP'), ('and', 'CC'), ('Natural', 'NNP'), ('Resources', 'NNP'), ('241', 'CD'), ('Energy', 'NNP'), ('241', 'CD'), ('Non', 'NNP'), ('-', ':'), ('fuel', 'NN'), ('Minerals', 'NNS'), ('260', 'CD'), ('Water', 'NNP'), ('263', 'CD'), ('14', 'CD'), ('Agriculture', 'NN'), (',', ','), ('Fisheries', 'NNP'), ('and', 'CC'), ('Forestry', 'NNP'), ('266', 'CD'), ('Agriculture', 'NNP'), ('266', 'CD'), ('Fisheries', 'NNS'), ('279', 'CD'), ('Forestry', 'NNP'), ('284', 'CD'), ('15', 'CD'), ('Transport', 'NN'), ('and', 'CC'), ('Communications', 'NNP'), ('286', 'CD'), ('Inland', 'NNP'), ('Transport', 'NNP'), ('286', 'CD'), ('Ports', 'NNP'), ('296', 'CD'), ('Shipping', 'VBG'), ('298', 'CD'), ('Civil', 'NNP'), ('Aviation', 'NNP'), ('301', 'CD'), ('The', 'DT'), ('Post', 'NNP'), ('Office', 'NNP'), ('306', 'CD'), ('16', 'CD'), ('Employment', 'NN'), ('310', 'CD'), ('The', 'DT'), ('Working', 'NNP'), ('Population', 'NNP'), ('310', 'CD'), ('Manpower', 'NNP'), ('Policy', 'NNP'), ('311', 'CD'), ('Employment', 'NNP'), ('Law', 'NNP'), ('316', 'CD'), ('Pay', 'NNP'), (',', ','), ('Flours', 'NNP'), ('of', 'IN'), ('Work', 'NNP'), ('and', 'CC'), ('Flolidays', 'NNP'), ('317', 'CD'), ('Industrial', 'NNP'), ('Relations', 'NNPS'), ('320', 'CD'), ('Health', 'NNP'), ('and', 'CC'), ('Safety', 'NNP'), ('at', 'IN'), ('Work', 'NNP'), ('327', 'CD'), ('17', 'CD'), ('Finance', 'NN'), ('332', 'CD'), ('The', 'DT'), ('Public', 'NNP'), ('Sector', 'NNP'), ('332', 'CD'), ('Financial', 'NNP'), ('Institutions', 'NNP'), ('342', 'CD'), ('18', 'CD'), ('Trade', 'NNP'), ('and', 'CC'), ('Payments', 'NNP'), ('352', 'CD'), ('Overseas', 'NNP'), ('Trade', 'NNP'), ('352', 'CD'), ('Balance', 'NNP'), ('of', 'IN'), ('Payments', 'NNS'), ('362', 'CD'), ('19', 'CD'), ('Promotion', 'NN'), ('of', 'IN'), ('the', 'DT'), ('Sciences', 'NNPS'), ('371', 'CD'), ('20', 'CD'), ('The', 'DT'), ('Arts', 'NNS'), ('390', 'CD'), ('21', 'CD'), ('The', 'DT'), ('Press', 'NNP'), ('405', 'CD'), ('22', 'CD'), ('Television', 'NN'), ('and', 'CC'), ('Radio', 'NNP'), ('413', 'CD'), ('23', 'CD'), ('Sport', 'NNP'), ('and', 'CC'), ('Recreation', 'NNP'), ('421', 'CD'), ('Page', 'NNP'), ('Appendix', 'NNP'), ('431', 'CD'), ('Currency', 'NNP'), ('431', 'CD'), ('Metric', 'NNP'), ('Equivalents', 'NNS'), ('for', 'IN'), ('British', 'JJ'), ('Weights', 'NNS'), ('and', 'CC'), ('Measures', 'VBZ'), ('431', 'CD'), ('Bibliography', 'NNP'), ('433', 'CD'), ('Index', 'NNP'), ('455', 'CD'), ('Diagrams', 'NNP'), ('United', 'NNP'), ('Kingdom', 'NNP'), ('population', 'NN'), ('changes', 'NNS'), ('and', 'CC'), ('projections', 'NNS'), ('9', 'CD'), ('The', 'DT'), ('Royal', 'NNP'), ('Family', 'NNP'), (':', ':'), ('genealogical', 'JJ'), ('tree', 'NN'), ('24', 'CD'), ('Policy', 'NNP'), ('-', ':'), ('making', 'NN'), ('in', 'IN'), ('the', 'DT'), ('European', 'NNP'), ('Community', 'NNP'), ('74', 'CD'), ('Functional', 'NNP'), ('analysis', 'NN'), ('of', 'IN'), ('defence', 'NN'), ('expenditure', 'NN'), ('1', 'CD'), ('978', 'CD'), ('-', ':'), ('79', 'CD'), ('105', 'CD'), ('Functional', 'JJ'), ('analysis', 'NN'), ('of', 'IN'), ('defence', 'NN'), ('personnel', 'NNS'), ('1', 'CD'), ('978', 'CD'), ('-', ':'), ('79', 'CD'), ('107', 'CD'), ('Personal', 'JJ'), ('income', 'NN'), ('and', 'CC'), ('expenditure', 'NN'), ('1', 'CD'), ('977', 'CD'), ('1', 'CD'), ('92', 'CD'), ('Energy', 'NNP'), ('trends', 'NNS'), ('1', 'CD'), ('967', 'CD'), ('-', ':'), ('77', 'CD'), ('242', 'CD'), ('Earnings', 'NNS'), (',', ','), ('wage', 'NN'), ('rates', 'NNS'), (',', ','), ('retail', 'JJ'), ('prices', 'NNS'), (',', ','), ('wages', 'NNS'), ('and', 'CC'), ('salaries', 'NNS'), ('1973', 'CD'), ('-', ':'), ('78', 'CD'), ('318', 'CD'), ('Maps', 'NNP'), ('Britain', 'NNP'), ('inside', 'IN'), ('back', 'RB'), ('cover', 'JJ'), ('Economic', 'NNP'), ('planning', 'NN'), ('regions', 'NNS'), ('and', 'CC'), ('new', 'JJ'), ('towns', 'NNS'), ('1', 'CD'), ('59', 'CD'), ('The', 'DT'), ('assisted', 'VBN'), ('areas', 'NNS'), ('208', 'CD'), ('Oil', 'NNP'), ('245', 'CD'), ('Gas', 'NNP'), ('249', 'CD'), ('Coal', 'NNP'), ('253', 'CD'), ('Electricity', 'NNP'), ('255', 'CD'), ('Some', 'DT'), ('minerals', 'NNS'), ('produced', 'VBN'), ('in', 'IN'), ('Britain', 'NNP'), ('â', 'NNP'), ('\\x80¢', 'VBZ'), ('261', 'CD'), ('Main', 'NNP'), ('railway', 'NN'), ('passenger', 'NN'), ('routes', 'VBZ'), ('293', 'CD'), ('Photographs', 'NNP'), ('Modern', 'NNP'), ('transport', 'VB'), ('The', 'DT'), ('Countryside', 'NNP'), ('Flowers', 'NNP'), ('Metallurgic', 'NNP'), ('technology', 'NN'), ('Industrial', 'NNP'), ('technology', 'NN'), ('Postal', 'NNP'), ('services', 'NNS'), ('Communications', 'NNP'), ('research', 'NN'), ('Prestel', 'NNP'), ('The', 'DT'), ('Police', 'NNP'), ('Thames', 'NNP'), ('Barrier', 'NNP'), ('and', 'CC'), ('Ironbridge', 'NNP'), ('Gorge', 'NNP'), ('Museum', 'NNP'), ('Sport', 'NNP'), ('facing', 'VBG'), ('page', 'NN'), ('38', 'CD'), ('between', 'IN'), ('pages', 'NNS'), ('38', 'CD'), ('and', 'CC'), ('39', 'CD'), ('facing', 'NN'), ('page', 'NN'), ('39', 'CD'), ('facing', 'NN'), ('page', 'NN'), ('1', 'CD'), ('34', 'CD'), ('between', 'IN'), ('pages', 'NNS'), ('1', 'CD'), ('34', 'CD'), ('and', 'CC'), ('1', 'CD'), ('35', 'CD'), ('facing', 'JJ'), ('page', 'NN'), ('294', 'CD'), ('between', 'IN'), ('pages', 'NNS'), ('294', 'CD'), ('and', 'CC'), ('295', 'CD'), ('facing', 'NN'), ('page', 'NN'), ('295', 'CD'), ('facing', 'NN'), ('page', 'NN'), ('390', 'CD'), ('between', 'IN'), ('pages', 'NNS'), ('390', 'CD'), ('and', 'CC'), ('391', 'CD'), ('facing', 'NN'), ('page', 'NN'), ('391', 'CD'), ('Acknowledgement', 'NNP'), ('is', 'VBZ'), ('made', 'VBN'), ('for', 'IN'), ('photographs', 'NN'), ('to', 'TO'), (':', ':'), ('British', 'JJ'), ('Railways', 'NNP'), ('Board', 'NNP'), ('for', 'IN'), ('Advanced', 'NNP'), ('passenger', 'NN'), ('train', 'NN'), ('(', '('), ('facing', 'VBG'), ('p', 'RB'), ('38', 'CD'), (');', 'JJ'), ('British', 'JJ'), ('Hovercraft', 'NNP'), ('Corporation', 'NNP'), ('Ltd', 'NNP'), ('for', 'IN'), (\"'\", 'POS'), ('Super', 'NNP'), ('4', 'CD'), (\"'\", \"''\"), ('hovercraft', 'NN'), ('(', '('), ('facing', 'VBG'), ('p', 'RB'), ('38', 'CD'), (');', 'JJ'), ('Eric', 'NNP'), ('Hosking', 'NNP'), (',', ','), ('F', 'NNP'), ('.', '.'), ('R', 'NNP'), ('.', '.'), ('P', 'NNP'), ('.', '.'), ('S', 'NNP'), ('.,', 'NNP'), ('F', 'NNP'), ('.', '.'), ('I', 'PRP'), ('.', '.'), ('I', 'PRP'), ('.', '.'), ('P', 'NNP'), ('.,', 'NNP'), ('for', 'IN'), ('Gentian', 'NNP'), (',', ','), ('Bee', 'NNP'), ('Orchid', 'NNP'), (',', ','), ('Primrose', 'NNP'), ('and', 'CC'), ('Cowslip', 'NNP'), ('(', '('), ('facing', 'VBG'), ('p', 'RB'), ('39', 'CD'), (');', 'JJ'), ('Superform', 'NNP'), ('Metals', 'NNPS'), ('Ltd', 'NNP'), ('iot', 'NN'), ('superplastic', 'JJ'), ('alloy', 'NN'), ('(', '('), ('facing', 'VBG'), ('p', 'RB'), ('134', 'CD'), (');', 'JJ'), ('International', 'NNP'), ('Computers', 'NNPS'), ('Ltd', 'NNP'), ('\\\\', 'NNP'), ('ot', 'JJ'), ('miniature', 'NN'), ('circuit', 'NN'), ('(', '('), ('between', 'IN'), ('pp', 'NN'), ('134', 'CD'), ('and', 'CC'), ('1', 'CD'), ('35', 'CD'), (');', 'JJ'), ('Tate', 'NNP'), ('Er', 'NNP'), ('Lyle', 'NNP'), ('Ltd', 'NNP'), ('for', 'IN'), ('sugar', 'NN'), ('-', ':'), ('based', 'VBN'), ('gum', 'NN'), ('(', '('), ('between', 'IN'), ('pp', 'NN'), ('1', 'CD'), ('34', 'CD'), ('and', 'CC'), ('1', 'CD'), ('35', 'CD'), (');', 'JJ'), ('Mears', 'NNP'), ('Bros', 'NNP'), ('Holdings', 'NNPS'), ('Ltd', 'NNP'), ('for', 'IN'), ('tower', 'NN'), ('(', '('), ('facing', 'VBG'), ('p', 'RB'), ('1', 'CD'), ('35', 'CD'), (');', 'NN'), ('United', 'NNP'), ('Kingdom', 'NNP'), ('Atomic', 'NNP'), ('Energy', 'NNP'), ('Authority', 'NNP'), ('for', 'IN'), ('nuclear', 'JJ'), ('fuel', 'NN'), ('reprocessing', 'NN'), ('(', '('), ('facing', 'VBG'), ('p', 'RB'), ('135', 'CD'), (');', 'JJ'), ('Metropolitan', 'NNP'), ('Police', 'NNP'), ('Publicity', 'NNP'), ('Branch', 'NNP'), ('for', 'IN'), ('traffic', 'NN'), ('control', 'NN'), ('room', 'NN'), ('and', 'CC'), ('information', 'NN'), ('room', 'NN'), ('(', '('), ('facing', 'VBG'), ('p', 'RB'), ('390', 'CD'), (');', 'NNS'), ('Davy', 'NNP'), ('-', ':'), ('Loewy', 'NNP'), ('Ltd', 'NNP'), ('for', 'IN'), ('support', 'NN'), ('structure', 'NN'), ('(', '('), ('between', 'IN'), ('pp', 'NN'), ('390', 'CD'), ('and', 'CC'), ('391', 'CD'), (').', 'NN')], [('Introduction', 'NN'), ('Britain', 'NNP'), ('1979', 'CD'), ('is', 'VBZ'), ('the', 'DT'), ('thirtieth', 'JJ'), ('official', 'JJ'), ('handbook', 'NN'), ('in', 'IN'), ('the', 'DT'), ('series', 'NN'), ('prepared', 'VBD'), ('and', 'CC'), ('revised', 'VBD'), ('each', 'DT'), ('year', 'NN'), ('by', 'IN'), ('Reference', 'NNP'), ('Division', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Central', 'NNP'), ('Office', 'NNP'), ('of', 'IN'), ('Information', 'NNP'), ('.', '.')], [('The', 'DT'), ('contents', 'NNS'), ('are', 'VBP'), ('based', 'VBN'), ('on', 'IN'), ('information', 'NN'), ('available', 'JJ'), ('up', 'RB'), ('to', 'TO'), ('September', 'NNP'), ('1', 'CD'), ('978', 'CD'), ('.', '.')], [('The', 'DT'), ('handbook', 'NN'), ('is', 'VBZ'), ('widely', 'RB'), ('known', 'VBN'), ('as', 'IN'), ('an', 'DT'), ('established', 'JJ'), ('work', 'NN'), ('of', 'IN'), ('reference', 'NN'), ('and', 'CC'), ('is', 'VBZ'), ('the', 'DT'), ('mainstay', 'NN'), ('of', 'IN'), ('the', 'DT'), ('reference', 'NN'), ('facilities', 'NNS'), ('provided', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('British', 'JJ'), ('Information', 'NNP'), ('Services', 'NNP'), ('in', 'IN'), ('many', 'JJ'), ('countries', 'NNS'), ('.', '.')], [('It', 'PRP'), ('is', 'VBZ'), ('distributed', 'VBN'), ('overÂ', 'JJ'), ('¬', 'NNP'), ('seas', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('limited', 'JJ'), ('free', 'JJ'), ('edition', 'NN'), ('and', 'CC'), ('is', 'VBZ'), ('on', 'IN'), ('sale', 'NN'), ('by', 'IN'), ('Her', 'NNP'), ('Majesty', 'NNP'), (\"'\", 'POS'), ('s', 'JJ'), ('Stationery', 'NNP'), ('Office', 'NNP'), ('throughout', 'IN'), ('the', 'DT'), ('world', 'NN'), ('.', '.')], [('Britain', 'NNP'), ('1979', 'CD'), ('is', 'VBZ'), ('primarily', 'RB'), ('concerned', 'VBN'), ('to', 'TO'), ('describe', 'VB'), ('the', 'DT'), ('machiÂ', 'NN'), ('¬', 'JJ'), ('nery', 'NN'), ('of', 'IN'), ('government', 'NN'), ('and', 'CC'), ('other', 'JJ'), ('institutions', 'NNS'), (',', ','), ('together', 'RB'), ('with', 'IN'), ('the', 'DT'), ('necessary', 'JJ'), ('physical', 'JJ'), ('and', 'CC'), ('social', 'JJ'), ('background', 'NN'), (',', ','), ('and', 'CC'), ('to', 'TO'), ('show', 'VB'), ('the', 'DT'), ('part', 'NN'), ('played', 'VBN'), ('by', 'IN'), ('government', 'NN'), ('in', 'IN'), ('the', 'DT'), ('life', 'NN'), ('of', 'IN'), ('the', 'DT'), ('country', 'NN'), ('.', '.')], [('It', 'PRP'), ('does', 'VBZ'), ('not', 'RB'), ('attempt', 'VB'), ('an', 'DT'), ('analytical', 'JJ'), ('approach', 'NN'), ('to', 'TO'), ('current', 'JJ'), ('events', 'NNS'), ('.', '.')], [('The', 'DT'), ('factual', 'JJ'), ('and', 'CC'), ('statistical', 'JJ'), ('information', 'NN'), ('it', 'PRP'), ('contains', 'VBZ'), ('is', 'VBZ'), ('comÂ', 'JJ'), ('¬', 'NNP'), ('piled', 'VBD'), ('with', 'IN'), ('the', 'DT'), ('co', 'NN'), ('-', ':'), ('operation', 'NN'), ('of', 'IN'), ('other', 'JJ'), ('government', 'NN'), ('departments', 'NNS'), ('and', 'CC'), ('agencies', 'NNS'), (',', ','), ('and', 'CC'), ('of', 'IN'), ('many', 'JJ'), ('other', 'JJ'), ('organisations', 'NNS'), ('.', '.')], [('Sources', 'NNS'), ('of', 'IN'), ('more', 'JJR'), ('detailed', 'JJ'), ('and', 'CC'), ('more', 'RBR'), ('topical', 'JJ'), ('information', 'NN'), ('(', '('), ('including', 'VBG'), ('statisÂ', 'NN'), ('¬', 'NNP'), ('tics', 'NNS'), (')', ')'), ('are', 'VBP'), ('mentioned', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('text', 'NN'), ('and', 'CC'), ('in', 'IN'), ('the', 'DT'), ('Bibliography', 'NNP'), ('towards', 'IN'), ('the', 'DT'), ('end', 'NN'), ('of', 'IN'), ('the', 'DT'), ('book', 'NN'), ('.', '.')], [('Reference', 'NNP'), ('Division', 'NNP'), ('Central', 'NNP'), ('Office', 'NNP'), ('of', 'IN'), ('Information', 'NNP'), (',', ','), ('London', 'NNP'), ('September', 'NNP'), ('1', 'CD'), ('978', 'CD'), ('THE', 'NNP'), ('PHYSICAL', 'NNP'), ('BACKGROUND', 'NNP'), ('Britain', 'NNP'), (',', ','), ('formally', 'RB'), ('known', 'VBN'), ('as', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('Kingdom', 'NNP'), ('of', 'IN'), ('Great', 'NNP'), ('Britain', 'NNP'), ('and', 'CC'), ('Northern', 'NNP'), ('Ireland', 'NNP'), (',', ','), ('constitutes', 'VBZ'), ('the', 'DT'), ('greater', 'JJR'), ('part', 'NN'), ('of', 'IN'), ('the', 'DT'), ('British', 'JJ'), ('Isles', 'NNP'), (',', ','), ('a', 'DT'), ('group', 'NN'), ('of', 'IN'), ('islands', 'NNS'), ('lying', 'VBG'), ('off', 'RP'), ('the', 'DT'), ('north', 'JJ'), ('-', ':'), ('west', 'JJS'), ('coast', 'NN'), ('of', 'IN'), ('mainland', 'NNP'), ('Europe', 'NNP'), ('.', '.')], [('The', 'DT'), ('largest', 'JJS'), ('islands', 'NNS'), ('are', 'VBP'), ('Great', 'NNP'), ('Britain', 'NNP'), ('(', '('), ('comprising', 'VBG'), ('the', 'DT'), ('mainlands', 'NNS'), ('of', 'IN'), ('England', 'NNP'), (',', ','), ('Wales', 'NNP'), ('and', 'CC'), ('Scotland', 'NNP'), (')', ')'), ('and', 'CC'), ('Ireland', 'NNP'), ('(', '('), ('comprising', 'VBG'), ('Northern', 'NNP'), ('Ireland', 'NNP'), ('and', 'CC'), ('the', 'DT'), ('Irish', 'NNP'), ('Republic', 'NNP'), (').', 'NN')], [('Off', 'IN'), ('the', 'DT'), ('southern', 'JJ'), ('coast', 'NN'), ('of', 'IN'), ('England', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('Isle', 'NNP'), ('of', 'IN'), ('Wight', 'NNP'), ('and', 'CC'), ('off', 'IN'), ('the', 'DT'), ('extreme', 'JJ'), ('south', 'JJ'), ('-', ':'), ('west', 'NN'), ('are', 'VBP'), ('the', 'DT'), ('Isles', 'NNP'), ('of', 'IN'), ('Scilly', 'NNP'), (';', ':'), ('off', 'RP'), ('north', 'JJ'), ('Wales', 'NNP'), ('is', 'VBZ'), ('Anglesey', 'NNP'), ('.', '.')], [('Western', 'JJ'), ('Scotland', 'NNP'), ('is', 'VBZ'), ('fringed', 'VBN'), ('by', 'IN'), ('numerous', 'JJ'), ('islands', 'NNS'), ('and', 'CC'), ('to', 'TO'), ('the', 'DT'), ('north', 'JJ'), ('-', ':'), ('east', 'NN'), ('are', 'VBP'), ('the', 'DT'), ('Orkneys', 'NNP'), ('and', 'CC'), ('Shet', 'NNP'), ('-', ':'), ('Tands', 'NNS'), ('.', '.')], [('All', 'PDT'), ('these', 'DT'), ('have', 'VBP'), ('administrative', 'JJ'), ('ties', 'NNS'), ('with', 'IN'), ('the', 'DT'), ('mainland', 'NN'), (',', ','), ('but', 'CC'), ('the', 'DT'), ('Isle', 'NNP'), ('of', 'IN'), ('Man', 'NNP'), ('in', 'IN'), ('the', 'DT'), ('Irish', 'NNP'), ('Sea', 'NNP'), ('and', 'CC'), ('the', 'DT'), ('Channel', 'NNP'), ('Islands', 'VBZ'), ('between', 'IN'), ('Great', 'NNP'), ('Britain', 'NNP'), ('and', 'CC'), ('France', 'NNP'), ('have', 'VBP'), ('a', 'DT'), ('large', 'JJ'), ('measure', 'NN'), ('of', 'IN'), ('administrative', 'JJ'), ('autonomy', 'NN'), ('and', 'CC'), ('are', 'VBP'), ('not', 'RB'), ('part', 'NN'), ('of', 'IN'), ('England', 'NNP'), (',', ','), ('Wales', 'NNP'), (',', ','), ('Scotland', 'NNP'), ('or', 'CC'), ('Northern', 'NNP'), ('Ireland', 'NNP'), ('.', '.')], [('TABLE', 'NN'), ('1', 'CD'), (':', ':'), ('Area', 'NN'), ('of', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('Kingdom', 'NNP'), ('Total', 'NNP'), ('Land', 'NNP'), ('Inland', 'NNP'), ('water', 'NN'), ('square', 'NN'), ('square', 'NN'), ('km', 'NN'), ('miles', 'NNS'), ('square', 'VBP'), ('km', 'JJ'), ('square', 'NN'), ('miles', 'NNS'), ('square', 'RB'), ('square', 'JJ'), ('km', 'NN'), ('miles', 'NNS'), ('United', 'NNP'), ('Kingdom', 'NNP'), ('244', 'CD'), (',', ','), ('103', 'CD'), ('94', 'CD'), (',', ','), ('249', 'CD'), ('Great', 'NNP'), ('Britain', 'NNP'), ('229', 'CD'), (',', ','), ('983', 'CD'), ('88', 'CD'), (',', ','), ('797', 'CD'), ('England', 'NNP'), ('130', 'CD'), (',', ','), ('441', 'CD'), ('50', 'CD'), (',', ','), ('363', 'CD'), ('Wales', 'NNP'), ('20', 'CD'), (',', ','), ('768', 'CD'), ('8', 'CD'), (',', ','), ('019', 'CD'), ('Scotland', 'NNP'), ('78', 'CD'), (',', ','), ('775', 'CD'), ('30', 'CD'), (',', ','), ('415', 'CD'), ('Northern', 'NNP'), ('Ireland', 'NNP'), ('14', 'CD'), (',', ','), ('120', 'CD'), ('5', 'CD'), (',', ','), ('452', 'CD'), ('241', 'CD'), (',', ','), ('019', 'CD'), ('227', 'CD'), (',', ','), ('536', 'CD'), ('129', 'CD'), (',', ','), ('725', 'CD'), ('20', 'CD'), (',', ','), ('640', 'CD'), ('77', 'CD'), (',', ','), ('171', 'CD'), ('13', 'CD'), (',', ','), ('483', 'CD'), ('93', 'CD'), (',', ','), ('058', 'CD'), ('87', 'CD'), (',', ','), ('852', 'CD'), ('50', 'CD'), (',', ','), ('087', 'CD'), ('7', 'CD'), (',', ','), ('969', 'CD'), ('29', 'CD'), (',', ','), ('796', 'CD'), ('5', 'CD'), (',', ','), ('206', 'CD'), ('3', 'CD'), (',', ','), ('084', 'CD'), ('2', 'CD'), (',', ','), ('447', 'CD'), ('716', 'CD'), ('128', 'CD'), ('1', 'CD'), (',', ','), ('604', 'CD'), ('637', 'CD'), ('1', 'CD'), (',', ','), ('191', 'CD'), ('945', 'CD'), ('276', 'CD'), ('49', 'CD'), ('619', 'CD'), ('246', 'CD'), ('Care', 'NN'), ('should', 'MD'), ('be', 'VB'), ('taken', 'VBN'), ('when', 'WRB'), ('studying', 'VBG'), ('British', 'JJ'), ('statistics', 'NNS'), ('to', 'TO'), ('note', 'VB'), ('whether', 'IN'), ('they', 'PRP'), ('refer', 'VBP'), ('to', 'TO'), ('England', 'NNP'), (',', ','), ('to', 'TO'), ('England', 'NNP'), ('and', 'CC'), ('Wales', 'NNP'), ('(', '('), ('considered', 'VBN'), ('together', 'RB'), ('for', 'IN'), ('many', 'JJ'), ('adminisÂ', 'JJ'), ('¬', 'NNP'), ('trative', 'NN'), ('and', 'CC'), ('other', 'JJ'), ('purposes', 'NNS'), ('),', 'VBP'), ('to', 'TO'), ('Great', 'NNP'), ('Britain', 'NNP'), (',', ','), ('which', 'WDT'), ('comprises', 'VBZ'), ('England', 'NNP'), (',', ','), ('Wales', 'NNP'), ('and', 'CC'), ('Scotland', 'NNP'), (',', ','), ('or', 'CC'), ('to', 'TO'), ('the', 'DT'), ('United', 'NNP'), ('Kingdom', 'NNP'), ('(', '('), ('Great', 'NNP'), ('Britain', 'NNP'), ('and', 'CC'), ('Northern', 'NNP'), ('Ireland', 'NNP'), (')', ')'), ('as', 'IN'), ('a', 'DT'), ('whole', 'NN'), ('.', '.')], [('United', 'NNP'), ('Kingdom', 'NNP'), ('statistics', 'NNS'), ('and', 'CC'), ('other', 'JJ'), ('data', 'NNS'), ('occasionally', 'RB'), ('include', 'VBP'), ('the', 'DT'), ('Isle', 'NNP'), ('of', 'IN'), ('Man', 'NNP'), (',', ','), ('588', 'CD'), ('square', 'JJ'), ('km', 'NN'), ('(', '('), ('227', 'CD'), ('sq', 'NN'), ('miles', 'NNS'), ('),', 'RB'), ('and', 'CC'), ('the', 'DT'), ('Channel', 'NNP'), ('Islands', 'NNP'), (',', ','), ('194', 'CD'), ('square', 'JJ'), ('km', 'NN'), ('(', '('), ('75', 'CD'), ('sq', 'NN'), ('miles', 'NNS'), (').', 'VBP')]]\n"
     ]
    }
   ],
   "source": [
    "# Tag parts of speech in sentences\n",
    "sentences = wordlists.sents()  # sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "pos_tagged = [nltk.pos_tag(sent) for sent in sentences]\n",
    "print(pos_tagged[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parts of speech are abbreviated as follows:\n",
    "* `NN` = singular noun, `NNS` = plural noun, `NNP` = singular proper noun, `NNPS` = plural proper noun\n",
    "* `IN` = preposition\n",
    "* `TO` = preposition or infinitive marker\n",
    "* `DT` = determiner\n",
    "* `CC` = coordinating conjunction\n",
    "* `JJ` = adjective\n",
    "* `VB` = verb\n",
    "* `RB` = adverb\n",
    "\n",
    "More abbreviations are explained [here](https://www.learntek.org/blog/categorizing-pos-tagging-nltk-python/) or can be queried with `nltk.help.upenn_tagset('TAG')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Dataset Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Narration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here - average sentence length, number of tables, dates covered, places covered..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Uniqueness and Variety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Narration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here - find most frequent words, lexical diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploratory Analysis (this section will be included for 2-3 datasets)\n",
    "[Code cells in this section will have one function each, preceded with comments in a markdown cell posing an exploratory research question]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 How is Britain and the UK portrayed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizations go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 How is Scotland portrayed?  Ireland?  Wales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizations go here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
