{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The National Bibliography of Scotland as Data\n",
    "Created August-September 2020 for the National Library of Scotland's Data Foundry by Lucy Havens, Digital Library Research Intern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About The National Bibliography of Scotland Dataset\n",
    "This dataset is the first version of the bibliographic records for the National Bibliography of Scotland. This version of the National Bibliography of Scotland references materials published in Scotland and/or is in language Scots and/or is in language Scottish Gaelic from National Library of Scotland's main catalogue. This is the first iteration of the new National Bibliography of Scotland, which was originally produced in April 2019. National Bibliography of Scotland is an ongoing programme of work.\n",
    "* Data format: metadata (as MARC XML)\n",
    "* Data creation process: manual entry\n",
    "* Data source: https://data.nls.uk/data/metadata-collections/national-bibliography-of-scotland/\n",
    "***\n",
    "### Table of Contents\n",
    "0. [Preparation](#0.-Preparation)\n",
    "1. [Data Cleaning and Standardisation](#1.-Data-Cleaning-and-Standardisation)\n",
    "2. [Summary Statistics](#2.-Summary-Statistics)\n",
    "3. [Exploratory Analysis](#3.-Exploratory-Analysis)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Preparation\n",
    "Import libraries to use for cleaning, summarising and exploring the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prevent SSL certificate failure\n",
    "import os, ssl\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
    "    getattr(ssl, '_create_unverified_context', None)):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Libraries for data loading\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Libraries for visualization\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Libraries for text analysis\n",
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "# from nltk.corpus import PlaintextCorpusReader\n",
    "# nltk.download('wordnet')\n",
    "# from nltk.corpus import wordnet\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.text import Text\n",
    "# from nltk.stem.porter import PorterStemmer \n",
    "# from nltk.probability import FreqDist\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# from nltk.tag import pos_tag\n",
    "# nltk.download('tagsets')  # part of speech tags\n",
    "# from nltk.draw.dispersion import dispersion_plot as displt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the large size of The National Bibliography of Scotland (NBS) data files, they aren't uploaded to the collections-as-data GitHub repo.  To load the NBS MARCXML data into this Notebook, please download the data from the [NLS Data Foundry website](https://data.nls.uk/data/metadata-collections/national-bibliography-of-scotland/).  Edit the file path below as necessary so that you can run this Notebook on your own computer.\n",
    "\n",
    "The NBS data is actually **metadata**, meaning descriptive data about data.  In this case, the metadata contains information about books that have been published in Scotland, published in the language Scots, or published in the language Scottish Gaelic.  The metadata is provided as MARC XML.  MARC is a metadata standard used in libraries.  XML is a file format that is more widely used than MARC, so MARC is often provided as MARC *XML* so that systems other than library databases can read the data.\n",
    "\n",
    "If you've never seen XML data before, check out [this sample](https://www.loc.gov/standards/marcxml/Sandburg/sandburg.xml) XML file of MARC metadata from the Library of Congress.  To learn more, I'd recommend starting with W3 Schools' [tutorial on XML](https://www.w3schools.com/xml/default.asp), which explains its purpose, structure (a tree), tag naming conventions, and much more.\n",
    "\n",
    "To load the NBS MARC XML file, we'll use the Python library [ElementTree](https://docs.python.org/3/library/xml.etree.elementtree.html).  ElementTree, which we abbreviate *ET*, loads XML data (or metadata, in our case) in a hierarchical structure, or tree.  To iterate through the metadata, we need to find the root, or top-most level, of the tree.  From there we can travel up and down to pull out metadata of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the file path in parentheses below to correspond to where the NBS MARC XML file that\n",
    "# you downloaded can be found on your computer (unless the file is in a folder named Downloads!)\n",
    "tree = ET.parse('data/National-Bibliography-of-Scotland-v1-dataset-MARC.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the metadata loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root tag: {http://www.loc.gov/MARC21/slim}collection\n",
      "Root's first child tag: {http://www.loc.gov/MARC21/slim}record\n",
      "Root's 4th grandchild tag:\n",
      "   {http://www.loc.gov/MARC21/slim}datafield\n",
      "     Datafield attribute: {'tag': '020', 'ind1': ' ', 'ind2': ' '}\n",
      "        Great grandchild tag: {http://www.loc.gov/MARC21/slim}subfield\n",
      "        Great grandchild attribute: {'code': 'a'}\n",
      "        Great grandchild text: 1850980284\n"
     ]
    }
   ],
   "source": [
    "print(\"Root tag:\", str(root.tag))\n",
    "# print(\"Root text:\", str(root.text))               # empty\n",
    "print(\"Root's first child tag:\", str(root[0].tag))\n",
    "print(\"Root's 4th grandchild tag:\")\n",
    "print(\"  \",root[0][4].tag)\n",
    "print(\"     Datafield attribute:\",root[0][4].attrib)\n",
    "print(\"        Great grandchild tag:\",root[0][4][0].tag)\n",
    "print(\"        Great grandchild attribute:\",root[0][4][0].attrib)\n",
    "print(\"        Great grandchild text:\",root[0][4][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that the MARC field is a combination of the `tag` and `code` we can see that the MARC field we've printed is `020$a`, which is for an International Standard Book Number (ISBN).\n",
    "\n",
    "**MARC** was first developed by the Library of Congress and has since been adopted by libraries around the world.  The NBS uses MARC Bibliographic, about which more can be read at [this website](https://www.loc.gov/marc/).  MARC contains hundreds of metadata fields that libraries can choose to use, with a certain number of required fields and many optional fields.  In MARC metadata, tags are indicated with 3-digit numbers, indicators are single-digit numbers, and subfields are indicated with lowercase letters. A space and pound sign (`#`) separates fields from indicators, and a dollar sign (`$`) separates the field from the subfield.  For example, the personal name (or primary author) metadata entry has:\n",
    "\n",
    "* **tag:** ``100``\n",
    "* **indicators:** ``0`` for forename and ``1`` for surname\n",
    "* **subfields:** ``$a`` for personal name, ``$b`` for numeration, ``$c`` for titles and other words associated with a name, ``$q`` for a fuller form of the author's name, ``$d`` for dates associated with a name\n",
    "\n",
    "A metadata entry for an author could look like:\n",
    "```\n",
    "100 1# $a Gregory, Ruth W.\n",
    "       $q (Ruth Wilhelme),\n",
    "       $d 1910-\n",
    "```\n",
    "Some MARC fields are repeatable, such as the *International Standard Book Number* (ISBN), while others are not, such as *Main entry -- Personal name* (author).  More detail and examples for commonly used fields are available [here](https://www.loc.gov/marc/umb/um07to10.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MARC**XML** use the same tags, indicators, and subfields as attributes inside tags `< >`.  For example, the MARC metadata entry above would be the following in MARCXML:\n",
    "```\n",
    "<datafield tag=\"100\" ind1=\"1\" ind2=\"\">\n",
    "    <subfield code=\"a\">Gregory, Ruth W.</subfield>\n",
    "    <subfield code=\"q\">(Ruth Wilhelme)</subfield>\n",
    "    <subfield code=\"d\">1910-</subfield>\n",
    "</datafield>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 Dataset Size\n",
    "First, let's get a sense of how much metadata we have in the *National Bibliography of Scotland* (NBS) dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records so far: 368961\n"
     ]
    }
   ],
   "source": [
    "records = root.getchildren()\n",
    "total_records = len(records)\n",
    "print(\"Total records so far:\",total_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I've print ``Total records so far`` rather than simply ``Total records``.  This is because the NBS is an in-progress work and we're using the first of what will be many future versions of the NBS.\n",
    "Let's see what metadata has been documented for the first record (or first child of the root):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag: 020\n",
      "  a 1850980284\n",
      "Tag: 020\n",
      "  a 9781850980285\n",
      "Tag: 035\n",
      "  a (StEdNL)2614-nlsdb-Voyager\n",
      "Tag: 100\n",
      "  Indicator 1: 1\n",
      "  a Dryden, Derek.\n",
      "Tag: 245\n",
      "  Indicator 1: 1\n",
      "  Indicator 2: 0\n",
      "  a Salmon fishing on the South Esk Estuary :\n",
      "  b Teachers' Booklet /\n",
      "  c devised by Derek Dryden ; series editor Norman Nichol ; cover illustration by Archie Williams.\n",
      "Tag: 260\n",
      "  a Hamilton :\n",
      "  b Hamilton College of Education,\n",
      "  c 1978.\n",
      "Tag: 300\n",
      "  a 14 p. :\n",
      "  b ill., maps ;\n",
      "  c 30 cm.\n",
      "Tag: 490\n",
      "  Indicator 1: 1\n",
      "  a Learning resources ;\n",
      "  v B78\n",
      "Tag: 700\n",
      "  Indicator 1: 1\n",
      "  a Nichol, Norman.\n",
      "Tag: 700\n",
      "  Indicator 1: 1\n",
      "  a Williams, Archie.\n",
      "Tag: 710\n",
      "  Indicator 1: 2\n",
      "  a Hamilton College of Education.\n",
      "Tag: 830\n",
      "  Indicator 2: 0\n",
      "  a Learning resources ;\n",
      "  v B78.\n",
      "Tag: 919\n",
      "  a NBS\n"
     ]
    }
   ],
   "source": [
    "for child in records[0]:\n",
    "    if 'datafield' in child.tag:\n",
    "        print('Tag:', child.attrib['tag'])\n",
    "        ind1 = re.match(\"\\d\", child.attrib['ind1'])\n",
    "        ind2 = re.match(\"\\d\", child.attrib['ind2'])\n",
    "        if ind1 != None:\n",
    "            print('  Indicator 1:', ind1[0])\n",
    "        if ind2 != None:\n",
    "            print('  Indicator 2:', ind2[0])\n",
    "            \n",
    "        grandchildren = child.getchildren()\n",
    "        for grandchild in grandchildren:\n",
    "            print(' ', grandchild.attrib['code'], grandchild.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try replacing the number `0` with any number less than 368,961 to see how different records use different combinations of metadata fields!  (Remember that a list's maximum index is always 1 less than the length of a list, because the indeces begin at 0, not 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2 Identifying Subsets of the Data\n",
    "Let's select a subset of MARC fields that we want to extract from the NBS MARCXML file we've loaded and put those selections in a **dataframe**.  Dataframes are essentially tables.  The Python library [Pandas](https://pandas.pydata.org/docs/), which we abbreviated `pd` at the start of this notebook, allows us to create dataframes and then run queries over their rows and columns to efficiently analyze the data.\n",
    "\n",
    "**Step 1:** First, we'll create a dictionary (a data type in Python) that matches up MARC field with the name of the type of metadata the field contains (note that we're only defining a *subset* of all the available metadata field information):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARC Tag: 100 | Tag Name: Author\n",
      "MARC Tag: 130 | Tag Name: Uniform title\n",
      "MARC Tag: 245 | Tag Name: Title statement\n",
      "MARC Tag: 260 | Tag Name: Publication, distribution, etc.\n",
      "MARC Tag: 650 | Tag Name: Subject added entry -- Topical term\n",
      "MARC Tag: 700 | Tag Name: Added entry -- Personal name\n",
      "MARC Tag: 710 | Tag Name: Added entry -- Corporate name\n"
     ]
    }
   ],
   "source": [
    "marc_tags = ['100', '130', '245', '260', '650', '700', '710',]\n",
    "marc_names = ['Author', 'Uniform title', 'Title statement', \n",
    "              'Publication, distribution, etc.', 'Subject added entry -- Topical term',\n",
    "              'Added entry -- Personal name', 'Added entry -- Corporate name']\n",
    "\n",
    "marc_dict = dict(zip(marc_tags,marc_names))\n",
    "for key,value in marc_dict.items():\n",
    "    print(\"MARC Tag:\", key, \"| Tag Name:\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** We'll also create dictionaries for select subfields, one for each tag in the dictionary from step 1, and put them into a dictionary where each subfield dictionary (value) is associated with its corresponding tag (key):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARC Tag: 100 | Subfields: {'a': 'Personal name'}\n",
      "MARC Tag: 130 | Subfields: {'a': 'Uniform title', 'l': 'Language of work', 'f': 'Date of work'}\n",
      "MARC Tag: 245 | Subfields: {'a': 'Title proper'}\n",
      "MARC Tag: 260 | Subfields: {'a': 'Place', 'b': 'Name', 'c': 'Date'}\n",
      "MARC Tag: 650 | Subfields: {'a': 'Topical term'}\n",
      "MARC Tag: 700 | Subfields: {'a': 'Personal name', 'q': 'Fuller name'}\n",
      "MARC Tag: 710 | Subfields: {'a': 'Corporate or jurisdiction name'}\n"
     ]
    }
   ],
   "source": [
    "author = {'a' : 'Personal name'}\n",
    "unif_t = {'a' : 'Uniform title', 'l' : 'Language of work', 'f' : 'Date of work'}\n",
    "title_stat = {'a' : 'Title proper'}\n",
    "pub_dist = {'a' : 'Place', 'b' : 'Name', 'c' : 'Date'}\n",
    "topic = {'a' : 'Topical term'}\n",
    "pers_name = {'a' : 'Personal name', 'q' : 'Fuller name'}\n",
    "corp_name = {'a' : 'Corporate or jurisdiction name'}\n",
    "\n",
    "marc_subfields = [author, unif_t, title_stat, pub_dist, topic, pers_name, corp_name]\n",
    "marc_tag_subfields = dict(zip(marc_tags, marc_subfields))\n",
    "for key,value in marc_tag_subfields.items():\n",
    "    print(\"MARC Tag:\", key, \"| Subfields:\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Now let's extract the metadata field values from the NBS MARCXML metadata for the tags and subfields we defined in steps 1 and 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid rewriting similar code lines, we'll write a function in which we\n",
    "# input a child element of the XML tree's root, a MARC tag, and a subfield of that tag,\n",
    "# and receive as output the text of the MARC field if it's found (and False if it's not found)\n",
    "\n",
    "def getSubfieldText(elem, marcTag, subfield):\n",
    "    if (elem.attrib['tag'] == marcTag) :\n",
    "            subelems = elem.getchildren()\n",
    "            for subelem in subelems:\n",
    "                if subelem.attrib['code'] == subfield:\n",
    "                    return subelem.text\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_authors, all_titles, all_langs, all_pub_dates, all_pub_places, all_topics = [], [], [], [], [], []\n",
    "for record in records:\n",
    "    has_author = False\n",
    "    has_title = False\n",
    "    has_lang = False\n",
    "    has_pub_date = False\n",
    "    has_pub_place = False\n",
    "    has_topic = False\n",
    "    \n",
    "    authors, titles, langs, pub_dates, pub_places, topics = [], [], [], [], [], []\n",
    "    \n",
    "    for child in record.findall('{http://www.loc.gov/MARC21/slim}datafield'):\n",
    "        # Get author name in field 100$a\n",
    "        author = getSubfieldText(child, \"100\", \"a\")\n",
    "        if author:\n",
    "            has_author = True\n",
    "            authors += [author]\n",
    "\n",
    "        # Get title in either field 130$a or 245$a\n",
    "        title1 = getSubfieldText(child, \"130\", \"a\")\n",
    "        title2 = getSubfieldText(child, \"245\", \"a\")\n",
    "        if title2:\n",
    "            has_title = True\n",
    "            titles += [title2]\n",
    "        elif title1:\n",
    "            has_title = True\n",
    "            titles += [title1]\n",
    "            \n",
    "        # Get language\n",
    "        lang = getSubfieldText(child, \"130\", \"l\")\n",
    "        if lang:\n",
    "            has_lang = True\n",
    "            langs += [lang]\n",
    "\n",
    "        # Get publication date\n",
    "        pub_date1 = getSubfieldText(child, \"130\", \"f\")\n",
    "        pub_date2 = getSubfieldText(child, \"260\", \"c\")\n",
    "        if pub_date2:\n",
    "            has_pub_date = True\n",
    "            pub_dates += [pub_date2]\n",
    "        elif pub_date1:\n",
    "            has_pub_date = True\n",
    "            pub_dates += [pub_date1]\n",
    "\n",
    "        # Get publication place\n",
    "        pub_place = getSubfieldText(child, \"260\", \"a\")\n",
    "        if pub_place:\n",
    "            has_pub_place = True\n",
    "            pub_places += [pub_place]\n",
    "\n",
    "        # Get topical terms\n",
    "        topic = getSubfieldText(child, \"650\", \"a\")\n",
    "        if topic:\n",
    "            has_topic = True\n",
    "            topics += [topic]\n",
    "        \n",
    "    # After iterating through all datafield elements of the record\n",
    "    # (the elements where MARC fields may be found), if a MARC field\n",
    "    # we searched for isn't found, then add an empty string for that\n",
    "    # record's MARC field text\n",
    "    if not has_author:\n",
    "        authors += [\"None\"]\n",
    "    if not has_title:\n",
    "        titles += [\"None\"]\n",
    "    if not has_lang:\n",
    "        langs += [\"None\"]\n",
    "    if not has_pub_date:\n",
    "        pub_dates += [\"None\"]\n",
    "    if not has_pub_place:\n",
    "        pub_places += [\"None\"]\n",
    "    if not has_topic:\n",
    "        topics += [\"None\"]\n",
    "\n",
    "    all_authors.append(authors)\n",
    "    all_titles.append(titles)\n",
    "    all_langs.append(langs)\n",
    "    all_pub_dates.append(pub_dates)\n",
    "    all_pub_places.append(pub_places)\n",
    "    all_topics.append(topics)\n",
    "    \n",
    "# There should be one sublist inside each all_xxx lists for every record (meaning they are all the same length)\n",
    "# The assertions below will throw an error if this is not the case, indicating that our function didn't work as expected\n",
    "assert len(all_topics) == len(all_titles)\n",
    "assert len(all_titles) == len(all_authors)\n",
    "assert len(all_authors) == len(all_langs)\n",
    "assert len(all_langs) == len(all_pub_places)\n",
    "assert len(all_pub_places) == len(all_pub_dates)\n",
    "assert len(all_pub_dates) == len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['None'],\n",
       " ['Adult education'],\n",
       " ['Birds', 'Birds'],\n",
       " ['Adult education'],\n",
       " ['Nature conservation'],\n",
       " ['Wages.'],\n",
       " ['None'],\n",
       " ['Scientific expeditions'],\n",
       " ['None'],\n",
       " ['None']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_topics[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Now we'll turn the lists we created of all topics, titles, authors, langauges, publication places, and publication dates into a dataframe, or table, using Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>language</th>\n",
       "      <th>publication_place</th>\n",
       "      <th>publication_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Dryden, Derek.]</td>\n",
       "      <td>[Salmon fishing on the South Esk Estuary :]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Hamilton :]</td>\n",
       "      <td>[1978.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Macpherson, Iain.]</td>\n",
       "      <td>[Attracting new students to adult education :]</td>\n",
       "      <td>[Adult education]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Edinburgh :]</td>\n",
       "      <td>[1989.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[None]</td>\n",
       "      <td>[The breeding birds of south-east Scotland :]</td>\n",
       "      <td>[Birds, Birds]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Edinburgh :]</td>\n",
       "      <td>[1998.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[None]</td>\n",
       "      <td>[Adult education, the challenge of change]</td>\n",
       "      <td>[Adult education]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Edinburgh]</td>\n",
       "      <td>[1975]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[None]</td>\n",
       "      <td>[Nature conservation in the Cairngorms :]</td>\n",
       "      <td>[Nature conservation]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Edinburgh :]</td>\n",
       "      <td>[[1989?].]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                                           title  \\\n",
       "0     [Dryden, Derek.]     [Salmon fishing on the South Esk Estuary :]   \n",
       "1  [Macpherson, Iain.]  [Attracting new students to adult education :]   \n",
       "2               [None]   [The breeding birds of south-east Scotland :]   \n",
       "3               [None]      [Adult education, the challenge of change]   \n",
       "4               [None]       [Nature conservation in the Cairngorms :]   \n",
       "\n",
       "                   topic language publication_place publication_date  \n",
       "0                 [None]   [None]      [Hamilton :]          [1978.]  \n",
       "1      [Adult education]   [None]     [Edinburgh :]          [1989.]  \n",
       "2         [Birds, Birds]   [None]     [Edinburgh :]          [1998.]  \n",
       "3      [Adult education]   [None]       [Edinburgh]           [1975]  \n",
       "4  [Nature conservation]   [None]     [Edinburgh :]       [[1989?].]  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First create a dictionary for each column that will be in the dataframe\n",
    "cols = {'author' : all_authors, 'title' : all_titles, 'topic' : all_topics, 'language' : all_langs, 'publication_place' : all_pub_places, 'publication_date' : all_pub_dates}\n",
    "df = pd.DataFrame(cols)\n",
    "df.head()   # this prints the first 5 rows of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>language</th>\n",
       "      <th>publication_place</th>\n",
       "      <th>publication_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>368956</th>\n",
       "      <td>[Lister, John,]</td>\n",
       "      <td>[Epigrams, and Jeux d'Esprit /]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Edinburgh :]</td>\n",
       "      <td>[1870.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368957</th>\n",
       "      <td>[A. T. G.]</td>\n",
       "      <td>[Border reminiscences. Annals of Thornlea [in ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Galashiels, ]</td>\n",
       "      <td>[[1899]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368958</th>\n",
       "      <td>[A. T. G.]</td>\n",
       "      <td>[\"Lammermoor leaves\" /]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Galashiels,]</td>\n",
       "      <td>[1898.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368959</th>\n",
       "      <td>[A. W. G.]</td>\n",
       "      <td>[Dissolution of parliament. A statesman's adve...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Edinburgh, ]</td>\n",
       "      <td>[[1880]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368960</th>\n",
       "      <td>[E. G.]</td>\n",
       "      <td>[The Sabbath trader.]</td>\n",
       "      <td>[Sunday., Sabbath., Merchants]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[Stirling :]</td>\n",
       "      <td>[1855.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                                              title  \\\n",
       "368956  [Lister, John,]                    [Epigrams, and Jeux d'Esprit /]   \n",
       "368957       [A. T. G.]  [Border reminiscences. Annals of Thornlea [in ...   \n",
       "368958       [A. T. G.]                            [\"Lammermoor leaves\" /]   \n",
       "368959       [A. W. G.]  [Dissolution of parliament. A statesman's adve...   \n",
       "368960          [E. G.]                              [The Sabbath trader.]   \n",
       "\n",
       "                                 topic language publication_place  \\\n",
       "368956                          [None]   [None]     [Edinburgh :]   \n",
       "368957                          [None]   [None]    [Galashiels, ]   \n",
       "368958                          [None]   [None]     [Galashiels,]   \n",
       "368959                          [None]   [None]     [Edinburgh, ]   \n",
       "368960  [Sunday., Sabbath., Merchants]   [None]      [Stirling :]   \n",
       "\n",
       "       publication_date  \n",
       "368956          [1870.]  \n",
       "368957         [[1899]]  \n",
       "368958          [1898.]  \n",
       "368959         [[1880]]  \n",
       "368960          [1855.]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()   # df.tail prints the last 5 rows of a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Cleaning and Standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Code cells in this section will have one function each, preceded by comments as markdown above the cell to narrate the cleaning process]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part-of-speech tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summary Statistics\n",
    "[Code cells in this section will have one function each, preceded with comments in a markdown cell narrating the summarisation process]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Frequencies and Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Narration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Uniqueness and Variety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Narration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here - most frequent words, sentence structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploratory Analysis (this section will be included for 2-3 datasets)\n",
    "[Code cells in this section will have one function each, preceded with comments in a markdown cell posing an exploratory research question]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 [exploratory research question 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizations go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 [exploratory research question 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizations go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
